# 利用新特性实现线程池

# 前置知识

## 线程相关函数

### std::ref的作用

在创建线程对象时，如果线程执行函数的参数有引用，那么就要用到这个函数

```cpp
int a=1;
std::thread t(func,std::ref(a));
t.join();//join的作用就是等待线程执行函数退出
```

### detach的作用

detach调用之后，目标线程成为了守护线程，驻留后台运行，与之关联的std::thread对象失去对目标线程的关联，无法通过std::thread对象获得对该线程的控制权，所以如果主线程退出，那么子线程也是会崩溃的

调用detach之后，joinable()会返回false，get_id会

## volatile的用法和意义

### **1. 禁止优化**

通常情况下，编译器可能会优化代码，例如将变量的值缓存到寄存器中，以减少内存访问次数。然而，如果一个变量被标记为 `volatile`，编译器会确保每次访问该变量时都从内存中读取值，而不是使用寄存器中的缓存值。

### **2. 告知编译器的含义**

`volatile` 提醒编译器，这个变量的值可能会被其他因素（如硬件或另一个线程）修改，因此不能假定变量的值是稳定的。

### volatile不保证线程安全

volatile仅保证对变量的读写不会被优化，不保证原子性

## 互斥量与锁

### mutex

不支持递归地对互斥量对象上锁，不支持拷贝构造和移动构造

**成员函数**

try_lock()函数：尝试锁住互斥量，如果互斥量被其他线程持有，则当前线程不会被阻塞，会直接返回false，下面是一个使用案例

```cpp
// 1-2-mutex1
#include <iostream>      // std::cout
#include <thread>        // std::thread
#include <mutex>         // std::mutex
volatile int counter(0); // non-atomic counter
std::mutex mtx;          // locks access to counter
void increases_10k()
{
    for (int i = 0; i < 10000; ++i)
    {
        // 1. 使用try_lock的情况
        if (mtx.try_lock()) // only increase if currently not locked:
        {
            ++counter;
            mtx.unlock();
        }
        // 2. 使用lock的情况
        // {
        //     mtx.lock();
        //     ++counter;
        //     mtx.unlock();
        // }
    }
}
int main()
{
    std::thread threads[10];
    for (int i = 0; i < 10; ++i)
        threads[i] = std::thread(increases_10k);
    for (auto &th : threads)
        th.join();
    std::cout << " successful increases of the counter " << counter << std::endl;
    return 0;
}
```

### unique_lock和lock_guard

二者都能实现自动加锁和解锁，但是unique_lock更灵活，它可以进行临时解锁和再上锁，比如在构造对象之后可以使用lck.unlock()就可以进行解锁，lck.lock()进行上锁，不需要等到析构的时候自动解锁，下面这个案例结合条件变量用到了unlock

```cpp
#include <iostream>
#include <deque>
#include <thread>
#include <mutex>
#include <condition_variable>
#include <unistd.h>
std::deque<int> q;//一个全局双端队列 std::deque<int> q 用于存储数据
std::mutex mu;//保证对队列的线程安全操作
std::condition_variable cond;//用于线程间的同步和通知
int count = 0;
void fun1()
{
		//生产者线程
    while (true)
    {
        std::unique_lock<std::mutex> locker(mu);
        q.push_front(++count);
        locker.unlock();
        cond.notify_one();
        sleep(3);//替换成std::this_thread::sleep_for(std::chrono::seconds(3));更好
    }
}
void fun2()
{
		//消费者线程
    while (true)
    {
        std::unique_lock<std::mutex> locker(mu);
        cond.wait(locker, []()
                  { return !q.empty(); });//wait会先释放自己持有的锁，然后检查条件，条件不符则沉睡等待唤醒
        //wait中的线程被notify之类的函数唤醒之后就会先尝试获取锁
        auto data = q.back();
        q.pop_back();
        locker.unlock();
        std::cout << "thread2 get value form thread1: " << data << std::endl;
    }
}
int main()
{
    std::thread t1(fun1);
    std::thread t2(fun2);
    t1.join();
    t2.join();
    return 0;
}
```

这个程序实现了一个**生产者-消费者模型**，主要功能是两个线程通过一个共享的队列进行数据交互：一个线程（`fun1`）负责生成数据并放入队列，另一个线程（`fun2`）负责从队列中取出数据并处理

调用wait的时候，必须使用unique_lock，因为当前线程调用wait之后被阻塞并且函数会解锁互斥量，直到另外某个线程掉哟哦那个notify_one或者notify_all唤醒当前线程，一旦当前线程获得通知，wait函数也是会自动调用lock再次获取锁

如果wait没有使用第二个参数，第一次调用默认条件不成立，直接解锁然后阻塞，直到被唤醒，唤醒后尝试获取锁，如果得不到就会阻塞，直到获取锁

如果wait包含第二个参数，如果第二个参数不满足，那么wait将解锁互斥量并堵塞到本行，直到某
一个线程调用notify_one或notify_all为止，被唤醒后，wait重新尝试获取互斥量，如果得不到，线
程会卡在这里，直到获取到互斥量，然后继续判断第二个参数，如果表达式为false，wait对互斥
量解锁，然后休眠，如果为true，则进行后面的操作

## 内存序问题

使用原子变量的load和store的时候会用到内存序

```cpp
shared_data.store(value, std::memory_order_release); // 写入
int value = shared_data.load(std::memory_order_acquire); // 读取
```

### 为什么写入用release

当一个线程在写入共享数据之前，通常需要先完成一些逻辑（比如准备数据）

写入操作（`store`）之前的所有写入指令（数据准备逻辑）都不能重排到写入操作之后。

```cpp
std::atomic<int> data = 0;
ready.store(true, std::memory_order_release); // 先存储 "ready" 状态，通知其他线程
```

### 为什么读取用acquire

读取共享数据的线程需要确保读取的共享数据是最新的

读取操作（`load`）之后的所有读取或写入指令（对共享数据的访问）都不能重排到读取操作之前

通过 `acquire`，确保当前线程读取共享数据时，能够看到所有由 `release` 写入的已完成的操作

```cpp
if(ready.load(std::memory_order_acquire){//检测ready状态，确保读到的是最新的值
		cout<<data<<endl;//执行读取操作
}
```

### acquire和release配合的内存同步

**happens-before关系**

1. 当一个线程 **`store`（写入）** 数据时，使用 `memory_order_release`，确保写入结果对其他线程可见。
2. 当另一个线程 **`load`（读取）** 数据时，使用 `memory_order_acquire`，确保读取的结果包含了之前线程 `store` 的结果。

如果一个线程的 `release` 操作和另一个线程的 `acquire` 操作之间发生了**因果关系**，则会建立**happens-before 关系**，即：

- `release` 线程的写入操作**先发生**。
- `acquire` 线程可以看到写入操作的结果。

### 案例

最后用经典的生产消费者模型体现release和acquire的作用

```cpp
#include <iostream> // std::cout
#include <atomic>   // std::atomic, std::memory_order_relaxed
#include <thread>   // std::thread
using namespace std;
atomic<int> thedata(0);
atomic<bool> ready = false;
void producer()
{
    thedata.store(43, std::memory_order_relaxed);
    ready.store(true, memory_order_release);
}
void consumer()
{
    while (!ready.load(memory_order_acquire))
        ;
    cout << "data=" << thedata.load(memory_order_relaxed) << endl;
}

int main()
{
    thread t1(producer);
    thread t2(consumer);
    t1.join();
    t2.join();
    
}
```

## 异步操作

### std::future

一个用来存储异步调用函数返回值的类型，如果异步调用过程需要同步，或者说后一个异步调用需要使用前一个异步调用的结果，这个时候需要用到这个类型

有两种future，一种是唯一future（std::future），另一种是std::shared_future，前者是仅有的一个指向其关联事件的实例，后一个可以有多个实例指向同一个关联事件

std::future是一个模板，例如std::future，模板参数就是期待返回的类型，虽然future被用于线程间通信，但其本身却并不提供同步访问

future使用的时机是当你不需要立刻得到一个结果的时候，你可以开启一个线程帮你去做一项任务，并期待这个任务的返回，但是std::thread并没有提供这样的机制，这就需要用到std::async和std::future（都在头文件中声明）

std::async返回一个std::future对象，而不是给你一个确定的值（所以当你不需要立刻使用此值的时候才需要用到这个机制）。当你需要使用这个值的时候，对future使用get()，线程就会阻塞直到future就绪，然后返回该值。

通过下面的案例来学习decltype, future, async的用法

```cpp
#include <iostream>
#include <future>
#include <thread>

using namespace std;
int func1()
{
    // this_thread::sleep_for(chrono::seconds(5));
    return 2;
}
int func2(int a, int b)
{
    // this_thread::sleep_for(chrono::seconds(5));
    return a + b;
}
void do_other_thing(){
    cout << "hello world" << endl;
}
int main()
{
    future<decltype(func1())> res = async(func1);
    do_other_thing();
    cout << "res=" << res.get() << endl;
    future<decltype(func2(0, 0))> res2 = async(func2, 10, 20);
    cout << "res2=" << res2.get() << endl;
}
```

跟thread类似，async允许你通过将额外的参数添加到调用中，来将附加参数传递给函数。如果传入的函数指针是某个类的成员函数，则还需要将类对象指针传入（直接传入，传入指针，或者是std::ref封装）。

### std::packaged_task

直接看代码就理解了，这是一种对任务的封装，以更简便的方式实现前面必须用async和future配合才能完成的事情

```cpp
#include <iostream> 
#include <future>
#include <thread>

using namespace std;
int add(int a,int b)
{
    return a+b;
}

void do_other_thing(){
    cout << "hello world" << endl;
}
int main()
{
    packaged_task<int(int, int)> task(add);//封装任务
    do_other_thing();
    future<int> res = task.get_future();//取得任务的future
    task(1, 2);//使得任务开始执行，否则对future调用get的时候获取不到值，会阻塞
    cout << res.get() << endl;
}
```

### std::promise

promise和packed_task很像，packed_task直接指定了任务的函数签名，也就是直接指定任务函数的参数类型和返回类型，而promise代表的是函数返回值的抽象，可以将promise作为任务函数的参数，在任务内将函数的返回值直接设定给promise，也可以达到将返回值传出函数的目的

```cpp
#include <iostream>
#include <future>
#include <thread>
#include <string>
using namespace std;
void print(promise<string> &p)
{
    p.set_value("here's the result you want.");
}

void do_other_thing()
{
    cout << "hello world" << endl;
}
int main()
{
    promise<string> pro;
    future<string> res = pro.get_future();
    thread t(print, std::ref(pro));
    do_other_thing();
    cout << res.get() << endl;
    t.join();
}
```

## std::function

唯一要记住的就是std::function不仅可以保存普通函数，还可以保存lambda表达式，还可以保存成员函数 

保存成员函数的时候，在定义function的模版参数的时候必须是const A&，在传入参数的时候第一个参数再传入对象的引用即可

```cpp
std::function<void(const A&,int)>func=&A::func1;
A a("hello");
func(a,1);
```

## 模版参数包

这个语法非常关键，是实现线程池可以执行任何函数的关键，而不是仅仅执行固定的类型

### 模板参数包的定义

模板参数包是通过 `...` 语法在模板参数列表中定义的。例如：

```
template <typename... Args>
void func(Args... args);
```

- `Args...` 表示一个模板参数包，可以接受零个或多个类型参数。
- `args...` 是函数参数包，可以接受零个或多个函数参数。

### 模版参数包的展开

模版参数包需要通过展开操作符…展开，可以用于

1. 函数参数

```cpp
template<typename... Args>
void func(Args... args){
cout<<...<<args<<endl;
}
```

1. 初始化列表

```cpp
template<typename... Args>
void func(Args... args){
		int arr[]={args...};
}
```

### 典型用法

1. 转发函数参数

顺便介绍一下std::invoke()函数，这是一种通用的工具函数，用于调用可调用对象

```cpp
template<class F, class... Args>
void wrapper(F&&f,Args&&...args){
		std::invoke(std::forward<F>(f),std::forward<Args>(args));
}
```

1. 函数对象的调用

```cpp
template<class F,class... Args>
auto callFunction(F&&f,Args&&... args)->decltype(f(args...)){
		return f(std::forward<Args>(args)...);		
}
```

# 实现

threadpool.hpp

```cpp
#pragma once
#include <vector>
#include <thread>
#include <queue>
#include <functional>
#include <mutex>
#include <condition_variable>
#include <atomic>
#include <future>

class ThreadPool
{
private:
    class TaskFunction
    {
    public:
        /*
        这里实际上不是任务函数，而是执行任务函数的lamdba函数
        */
        std::function<void()> func_;
        TaskFunction(){}
    };
    using TaskFuncPtr = std::shared_ptr<TaskFunction>;

    /*
    线程池中的线程
    */
    std::vector<std::unique_ptr<std::thread>> threads_;
    /*
    queue是一种先进先出的队列容器，所以这是一个存放任务的任务队列
    */
    std::queue<TaskFuncPtr> taskqueue_;
    /*
    任务队列的互斥锁
    */
    std::mutex mutex_;
    /*
    任务队列的条件变量
    */
    std::condition_variable condition_;
    /*
    在析构函数中将stop_的值设为true，如果想让线程池停止工作，将其置为true
    */
    std::atomic_bool stop_{false};
    /*
    初始线程数
    */
    size_t threadNum_ = 0;

    /*
    其实不能拿tasks_.empty()==true作为所有任务运行结束的标志，而是应该设立一个原子变量来统计还正在运行的线程的数量，线程在准备执行task中的lamdba函数之前就会给这个变量+1，执行结束之后就会立刻-1
    */
    std::atomic<int> runningNum_{0};

    /**
     * @brief 线程从任务队列中取出任务的动作，任务会被存储到task引用中
     *
     * @param task 这是一个输出型参数
     * @return true 成功取出
     * @return false 发生了某种意外情况（被唤醒之后发现任务队列是空的）或者整个线程池该终止运行了
     */
    bool get(TaskFuncPtr &task);

public:
    /**
     * @brief Construct a new Thread Pool object
     * 什么也不干，初始化工作留给init函数
     */
    ThreadPool(){}

    /*
    在析构函数中终止线程
    */
    ~ThreadPool(){
        stop();
    }

    /**
     * @brief 初始化线程池
     *
     * @param num 指定线程池中最初的线程数
     * @return true 成功
     * @return false 失败
     */
    bool init(size_t num);
    /**
     * @brief 启动线程池，在线程池中创建指定数量的线程
     *
     * @return true
     * @return false
     */
    bool start();
    /**
     * @brief 终止线程池，置终止标记位为true
     *
     */
    void stop();
    /**
     * @brief 每一个线程的主函数
     *
     */
    void run();

    /**
     * @brief 获取目前线程池中的线程个数
     *
     * @return int 线程个数
     */
    size_t getThreadSize()
    {
        std::unique_lock<std::mutex> lock(mutex_);
        return threads_.size();
    }
    /**
     * @brief 获取目前任务的个数
     *
     * @return size_t 任务的个数
     */
    size_t getTaskNum()
    {
        std::unique_lock<std::mutex> lock(mutex_);
        return taskqueue_.size();
    }

    /**
     * @brief 等待当前任务队列中，所有工作全部结束
     * 这个是给主线程调用的，一定要先于stop调用，因为要确保所有任务都执行完之后再结束
     * @param millsecond 等待的时间，-1表示永远等待
     * @return true 所有工作都处理完成了
     * @return false 超时退出了
     */
    bool waitForAllDone(int millsecond = -1);

    /**
     * @brief 检查线程池的停止标记位是否被置为true 
     * 
     * @return true 线程池该停止运行了
     * @return false 线程池还没有停止运行
     */
    bool isTerminated(){
        return stop_.load();
    }

    /**
     * @brief 传入可执行对象和参数之后，封装任务，将任务将入任务队列
     *
     * @tparam F 可调用对象的类型，这个会被编译器推导出来，可能是函数指针类型，也可能是匿名函数类型，或者std::function类型
     * @tparam Args 模版参数包，表示一组类型参数的集合
     * @param timeout
     * @param f 具体的可调用对象
     * @param args Args&&...代表一个展开的参数包，每个参数都是万能引用
     * @return std::future<decltype(f(args...))> 返回任务函数的异步结果
     */
    template <class F, class... Args>
    auto exec(F &&f, Args &&...args) -> std::future<decltype(f(args...))>
    {
        using RetType = decltype(f(args...)); // 定义任务函数的返回类型
        auto task = std::make_shared<std::packaged_task<RetType()>>(std::bind(std::forward<F>(f), std::forward<Args>(args)...));
        TaskFuncPtr fptr = std::make_shared<TaskFunction>();
        fptr->func_ = [task]()
        {
            (*task)();
        };
        std::unique_lock<std::mutex> lock(mutex_);
        taskqueue_.push(fptr);
        condition_.notify_one();
        return task->get_future();
    }
};

```

threadpool.cpp

```cpp
#include "threadpool.hpp"
bool ThreadPool::init(size_t num)
{
    std::unique_lock<std::mutex> lock(mutex_);
    //这个if是为了防止重复调用init，第一次成功调用init之后只是设置了threadNum_的值，使其不为0
    if (!threads_.empty()||threadNum_==0)
        return false;
    threadNum_ = num;
    return true;
}
bool ThreadPool::start()
{
    std::unique_lock<std::mutex> lock(mutex_);
    if (!threads_.empty())
        return false;
    for (size_t i = 0; i < threadNum_; i++)
    {
        threads_.emplace_back(std::make_unique<std::thread>(&ThreadPool::run, this));
    }
    return true;
}
void ThreadPool::stop()
{
    {
        std::unique_lock<std::mutex> lock(mutex_);
        stop_.store(true);
        condition_.notify_all(); // 唤醒所有等待的线程，这些线程醒来之后会检查stop_及时知道该停止了
    }
    /*
    如果没有上面那个大括号，那么锁就不会及时释放，导致在下面调用join等待所有线程退出的时候，其他线程在调用get的时候也要获取锁，就会获取不到锁，而导致线程无法正常退出
    */
    for (auto iter = threads_.begin(); iter != threads_.end(); iter++)
    {
        if ((*iter)->joinable())
        {
            (*iter)->join();
        }
    }
    // 由于前面的线程已经完成了他们的任务且不再参与任何操作，所以这里可以不加锁
    threads_.clear();
}

bool ThreadPool::get(TaskFuncPtr &task)
{
    std::unique_lock<std::mutex> lock(mutex_); // 接下来要操作任务队列了，先加锁
    if (taskqueue_.empty())
    {
        // 任务队列是空的，则条件等待即可
        condition_.wait(lock, [this]
                        { return stop_.load() || !taskqueue_.empty(); });
        // 被唤醒只有两种可能：1. 整个线程池该终止了 2. 任务队列不为空
    }
    // 被唤醒之后再检查一下整个线程池是不是该终止了
    if (stop_.load())
        return false;
    // 再检查一下任务队列确实不为空，防止条件变量的虚假唤醒，同时也为了确保任务队列不为空时才取出任务
    if (!taskqueue_.empty())
    {
        task = std::move(taskqueue_.front()); // 避免拷贝构造，task是一个左值引用，指向外部变量，这里会触发移动构造，让外部的变量接管这里的资源
        taskqueue_.pop();
        return true;
    }
    return false;
}
void ThreadPool::run()
{
    /*
    不停地尝试获取任务，然后执行任务
    */
    while (!isTerminated())
    {
        TaskFuncPtr task;
        bool ok = get(task);
        if (ok)
        {
            runningNum_.fetch_add(1);
            task->func_(); // 执行任务类中提前保存好的lamdba函数
            runningNum_.fetch_sub(1);
            std::unique_lock<std::mutex> lock(mutex_);
            //子线程执行完自己的任务之后，看看任务队列是否为空，且是否还有其他正在运行的线程。如果没有其他正在运行的线程，且此时任务队列为空，那说明所有分配的任务都执行结束了，可以通知主线程了（配合waitForAllDone使用）
            if (runningNum_.load() == 0 && taskqueue_.empty())
            {
                condition_.notify_all();
            }
        }
    }
}

bool ThreadPool::waitForAllDone(int millsecond)
{
    std::unique_lock<std::mutex> lock(mutex_);
    if (taskqueue_.empty() && runningNum_.load() == 0)
        return true;
    if (millsecond < 0){
        condition_.wait(lock, [this]
                        { return taskqueue_.empty() && runningNum_.load() == 0; });
        return true;
    }
    else
        return condition_.wait_for(lock, std::chrono::milliseconds(millsecond), [this]
                                   { return taskqueue_.empty() && runningNum_.load() == 0; });//wait_for函数可以指定一个超时的时间参数，如果没有在时间内等到条件满足就会返回false，否则返回true
}
```

main.cpp

```cpp
#include <iostream>
#include "threadpool.hpp"
using namespace std;
void func0()
{
    cout << "func0()" << endl;
}
void func1(int a)
{
    cout << "func1() a=" << a << endl;
}
void func2(int a, string b)
{
    cout << "func1() a=" << a << ", b=" << b << endl;
}

void test1()
{
    ThreadPool threadpool;
    threadpool.init(3);
    threadpool.start();
    threadpool.exec(func0);
    threadpool.exec(func1, 2);
    threadpool.exec(func2, 1, "hello world");
    threadpool.stop();
}

int func1_future(int a)
{
    cout << "func1_future() a=" << a << endl;
    return a;
}
string func2_future(int a, string b)
{
    cout << "func2_future() a=" << a << ", b=" << b << endl;
    return b;
}

void test2_future()
{
    ThreadPool threadpool;
    threadpool.init(3);
    threadpool.start();
    auto res = threadpool.exec(func1_future, 2);
    auto res2 = threadpool.exec(func2_future, 2, "hello world");
    threadpool.waitForAllDone();//这里等待所有任务执行结束，这样就能确保下面future获得结果的时候不用阻塞
    cout << "res1=" << res.get() << endl;
    cout << "res2=" << res2.get() << endl;
    
    threadpool.stop();
}
class Test
{
    string name_;

public:
    int test(int i)
    {
        cout << name_ << ", i=" << i << endl;
        return i;
    }
    void setName(const string &str)
    {
        name_ = str;
    }
};
void test3_bind(){
    ThreadPool pool;
    pool.init(3);
    pool.start();
    Test t1;
    Test t2;
    t1.setName("test t1");
    t2.setName("test t2");
    auto res1=pool.exec(std::bind(&Test::test,&t1,std::placeholders::_1),10);
    auto res2=pool.exec(std::bind(&Test::test,&t2,std::placeholders::_1),11);
    pool.waitForAllDone();
    cout << "运行结束，结果分别是：" << res1.get() << " " << res2.get() << endl;
}

int main()
{
    //test3_bind();
    cout << __cplusplus << endl;
}
```